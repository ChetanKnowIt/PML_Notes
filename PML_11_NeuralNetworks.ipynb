{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmCgAoO+E1LrjfJRn11eR9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChetanKnowIt/PML_Notes/blob/main/PML_11_NeuralNetworks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rD64W8Ud8f4",
        "outputId": "2c7a9465-4bc6-44a8-eb6c-1e4179f8b458"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_path = '/content/gdrive/MyDrive/Datasets/tinydata.csv'\n",
        "tinydata = pd.read_csv(t_path, index_col = 0)\n",
        "dum_tiny = pd.get_dummies(tinydata, drop_first=True)\n",
        "sgd = SGDClassifier(loss='log_loss', random_state = 2022)\n",
        "X = dum_tiny.drop(\"Acceptance_like\", axis = 1)\n",
        "y = dum_tiny['Acceptance_like']"
      ],
      "metadata": {
        "id": "ddABKT08eKl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgd.fit(X, y)\n",
        "print(sgd.coef_)\n",
        "print(sgd.intercept_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "5SbQ_axgewAX",
        "outputId": "8417022c-963a-46bd-a39f-8584b8c738d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-84b71e8694a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \"\"\"\n\u001b[0;32m--> 883\u001b[0;31m         return self._fit(\n\u001b[0m\u001b[1;32m    884\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     ):\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"classes_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[0;31m# delete the attribute otherwise _partial_fit thinks it's not the first call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36m_validate_params\u001b[0;34m(self, for_partial_fit)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_functions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The loss %s is not supported. \"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"squared_loss\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The loss log_loss is not supported. "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tst_tiny = np.array([[0.3,0.4]])\n",
        "y_pred = sgd.predict(tst_tiny)\n",
        "print(y_pred)\n",
        "y_pred_prob = sgd.predict_proba(tst_tiny)\n",
        "print(y_pred_prob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "KcrnNfT4e2QH",
        "outputId": "1c1105e0-7cf0-4fac-cc6a-bc28368c2674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFittedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-6f7137a7aef9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtst_tiny\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst_tiny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_pred_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst_tiny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mVector\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \"\"\"\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0mthis\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mwould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \"\"\"\n\u001b[0;32m--> 405\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: This SGDClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### MLP\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(2,), activation=\"logistic\", random_state = 2022)\n",
        "mlp.fit(X, y)\n",
        "print(mlp.coef_)\n",
        "print(mlp.intercept_)\n",
        "tst_tiny = np.array([[0.3,0.4]])\n",
        "y_pred = mlp.predict(tst_tiny)\n",
        "print(y_pred)\n",
        "y_pred_prob = mlp.predict_proba(tst_tiny)\n",
        "print(y_pred_prob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "Famdnhv0nors",
        "outputId": "f089a41b-7677-49a3-8cce-543325a5f2e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-b13279ec134d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"logistic\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2022\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtst_tiny\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'MLPClassifier' object has no attribute 'coef_'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP Pipeline \n",
        "### Multi Layer Classifier for Bankruptcy"
      ],
      "metadata": {
        "id": "qmGnGBg7EhND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "kekLF6pJCUHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "bank_path = '/content/gdrive/MyDrive/Datasets/Bankruptcy/Bankruptcy.csv'\n",
        "Bankruptcy = pd.read_csv(bank_path)\n",
        "X = Bankruptcy.drop(['YR','D'], axis=1)\n",
        "y = Bankruptcy['D']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, \n",
        "                                                    random_state=2022, train_size=0.7)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eIvUc-RE-Za",
        "outputId": "74facd0f-156d-4429-dcb6-3a3670fd7462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mm = MinMaxScaler()\n",
        "mlp = MLPClassifier(activation = 'logistic', random_state =2022)\n",
        "pipe = Pipeline([('MM',mm),('MLP',mlp)])"
      ],
      "metadata": {
        "id": "krr2vfrUFQUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Koo0kxSXFu-N",
        "outputId": "60309b19-1ed5-44b3-b2f0-53b2e1533371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('MM', MinMaxScaler()),\n",
              "                ('MLP',\n",
              "                 MLPClassifier(activation='logistic', random_state=2022))])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pipe.predict(X_test)\n",
        "#print(y_pred)\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "y_pred_prob = pipe.predict_proba(X_test)[:,1]\n",
        "#print(y_pred_prob)\n",
        "print(roc_auc_score(y_test, y_pred_prob))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujrIbyyFF0Wv",
        "outputId": "803ba492-aa27-4d14-de9a-243561adc444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9\n",
            "0.9425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results with MLP:\n",
        "\n",
        "| **Metric** | **Score** |\n",
        "|------------|-----------|\n",
        "| Accuracy   | 0.9       |\n",
        "| roc_auc    | 0.94      |"
      ],
      "metadata": {
        "id": "QMR9w66lGw9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### USING GRID SEARCH CV\n",
        "\n",
        "pipe = Pipeline([('MM',mm),('MLP',mlp)])\n",
        "pipe.get_params()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJO1siWTGxfV",
        "outputId": "7f144629-141e-4a7d-9831-257cef583871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'memory': None,\n",
              " 'steps': [('MM', MinMaxScaler()),\n",
              "  ('MLP', MLPClassifier(activation='logistic', random_state=2022))],\n",
              " 'verbose': False,\n",
              " 'MM': MinMaxScaler(),\n",
              " 'MLP': MLPClassifier(activation='logistic', random_state=2022),\n",
              " 'MM__clip': False,\n",
              " 'MM__copy': True,\n",
              " 'MM__feature_range': (0, 1),\n",
              " 'MLP__activation': 'logistic',\n",
              " 'MLP__alpha': 0.0001,\n",
              " 'MLP__batch_size': 'auto',\n",
              " 'MLP__beta_1': 0.9,\n",
              " 'MLP__beta_2': 0.999,\n",
              " 'MLP__early_stopping': False,\n",
              " 'MLP__epsilon': 1e-08,\n",
              " 'MLP__hidden_layer_sizes': (100,),\n",
              " 'MLP__learning_rate': 'constant',\n",
              " 'MLP__learning_rate_init': 0.001,\n",
              " 'MLP__max_fun': 15000,\n",
              " 'MLP__max_iter': 200,\n",
              " 'MLP__momentum': 0.9,\n",
              " 'MLP__n_iter_no_change': 10,\n",
              " 'MLP__nesterovs_momentum': True,\n",
              " 'MLP__power_t': 0.5,\n",
              " 'MLP__random_state': 2022,\n",
              " 'MLP__shuffle': True,\n",
              " 'MLP__solver': 'adam',\n",
              " 'MLP__tol': 0.0001,\n",
              " 'MLP__validation_fraction': 0.1,\n",
              " 'MLP__verbose': False,\n",
              " 'MLP__warm_start': False}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = { 'MLP__hidden_layer_sizes': [(20,10,5),(10,5),(50,)],\n",
        "          'MLP__activation': ('logistic','tanh'),\n",
        "          'MLP__learning_rate':('constant','invscaling','adaptive'),\n",
        "          'MLP__learning_rate_init':(0.001,0.3,0.5)\n",
        "          }\n",
        "\n",
        "kfold = StratifiedKFold(n_splits =5, shuffle = True, random_state = 2022)\n",
        "gcv = GridSearchCV(pipe, param_grid = params, cv = kfold, scoring = 'roc_auc', verbose = 3)          \n",
        "gcv.fit(X,y)\n",
        "print(gcv.best_params_)\n",
        "print(gcv.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQvG6xjNHLiC",
        "outputId": "e4cdeb63-8930-474b-cc85-732dab33977f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
            "[CV 1/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.001;, score=0.951 total time=   0.1s\n",
            "[CV 2/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.001;, score=0.780 total time=   0.1s\n",
            "[CV 3/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.001;, score=1.000 total time=   0.1s\n",
            "[CV 4/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.001;, score=0.899 total time=   0.1s\n",
            "[CV 5/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.001;, score=0.994 total time=   0.1s\n",
            "[CV 1/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.3;, score=0.005 total time=   0.0s\n",
            "[CV 2/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.3;, score=0.071 total time=   0.0s\n",
            "[CV 3/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.3;, score=0.456 total time=   0.1s\n",
            "[CV 4/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.3;, score=0.006 total time=   0.0s\n",
            "[CV 5/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.3;, score=0.006 total time=   0.0s\n",
            "[CV 1/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.5;, score=0.264 total time=   0.0s\n",
            "[CV 2/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.5;, score=0.511 total time=   0.1s\n",
            "[CV 3/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.5;, score=0.071 total time=   0.1s\n",
            "[CV 4/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.5;, score=0.213 total time=   0.1s\n",
            "[CV 5/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.5;, score=0.012 total time=   0.0s\n",
            "[CV 1/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.001;, score=0.951 total time=   0.2s\n",
            "[CV 2/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.001;, score=0.780 total time=   0.1s\n",
            "[CV 3/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.001;, score=1.000 total time=   0.1s\n",
            "[CV 4/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.001;, score=0.899 total time=   0.1s\n",
            "[CV 5/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.001;, score=0.994 total time=   0.1s\n",
            "[CV 1/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.3;, score=0.005 total time=   0.0s\n",
            "[CV 2/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.3;, score=0.071 total time=   0.0s\n",
            "[CV 3/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.3;, score=0.456 total time=   0.0s\n",
            "[CV 4/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.3;, score=0.006 total time=   0.1s\n",
            "[CV 5/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.3;, score=0.006 total time=   0.0s\n",
            "[CV 1/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.5;, score=0.264 total time=   0.0s\n",
            "[CV 2/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.5;, score=0.511 total time=   0.0s\n",
            "[CV 3/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.5;, score=0.071 total time=   0.0s\n",
            "[CV 4/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.5;, score=0.213 total time=   0.1s\n",
            "[CV 5/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.5;, score=0.012 total time=   0.0s\n",
            "[CV 1/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.001;, score=0.951 total time=   0.1s\n",
            "[CV 2/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.001;, score=0.780 total time=   0.2s\n",
            "[CV 3/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.001;, score=1.000 total time=   0.2s\n",
            "[CV 4/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.001;, score=0.899 total time=   0.3s\n",
            "[CV 5/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.001;, score=0.994 total time=   0.3s\n",
            "[CV 1/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.3;, score=0.005 total time=   0.1s\n",
            "[CV 2/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.3;, score=0.071 total time=   0.0s\n",
            "[CV 3/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.3;, score=0.456 total time=   0.0s\n",
            "[CV 4/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.3;, score=0.006 total time=   0.0s\n",
            "[CV 5/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.3;, score=0.006 total time=   0.0s\n",
            "[CV 1/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.5;, score=0.264 total time=   0.1s\n",
            "[CV 2/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.5;, score=0.511 total time=   0.0s\n",
            "[CV 3/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.5;, score=0.071 total time=   0.0s\n",
            "[CV 4/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.5;, score=0.213 total time=   0.0s\n",
            "[CV 5/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.5;, score=0.012 total time=   0.0s\n",
            "[CV 1/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.001;, score=0.901 total time=   0.1s\n",
            "[CV 2/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.001;, score=0.945 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.001;, score=0.828 total time=   0.1s\n",
            "[CV 4/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.001;, score=0.870 total time=   0.1s\n",
            "[CV 5/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.001;, score=0.941 total time=   0.1s\n",
            "[CV 1/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.3;, score=0.044 total time=   0.0s\n",
            "[CV 2/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.3;, score=0.099 total time=   0.0s\n",
            "[CV 3/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.3;, score=0.905 total time=   0.0s\n",
            "[CV 4/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.3;, score=0.030 total time=   0.0s\n",
            "[CV 5/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.3;, score=0.112 total time=   0.0s\n",
            "[CV 1/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.5;, score=0.330 total time=   0.0s\n",
            "[CV 2/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.5;, score=0.352 total time=   0.0s\n",
            "[CV 3/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.5;, score=0.527 total time=   0.0s\n",
            "[CV 4/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.5;, score=0.417 total time=   0.0s\n",
            "[CV 5/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.5;, score=0.627 total time=   0.0s\n",
            "[CV 1/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.001;, score=0.901 total time=   0.1s\n",
            "[CV 2/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.001;, score=0.945 total time=   0.1s\n",
            "[CV 3/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.001;, score=0.828 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.001;, score=0.870 total time=   0.1s\n",
            "[CV 5/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.001;, score=0.941 total time=   0.1s\n",
            "[CV 1/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.3;, score=0.044 total time=   0.0s\n",
            "[CV 2/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.3;, score=0.099 total time=   0.0s\n",
            "[CV 3/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.3;, score=0.905 total time=   0.0s\n",
            "[CV 4/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.3;, score=0.030 total time=   0.0s\n",
            "[CV 5/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.3;, score=0.112 total time=   0.0s\n",
            "[CV 1/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.5;, score=0.330 total time=   0.0s\n",
            "[CV 2/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.5;, score=0.352 total time=   0.0s\n",
            "[CV 3/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.5;, score=0.527 total time=   0.0s\n",
            "[CV 4/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.5;, score=0.417 total time=   0.0s\n",
            "[CV 5/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.5;, score=0.627 total time=   0.0s\n",
            "[CV 1/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.001;, score=0.901 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.001;, score=0.945 total time=   0.1s\n",
            "[CV 3/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.001;, score=0.828 total time=   0.1s\n",
            "[CV 4/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.001;, score=0.870 total time=   0.1s\n",
            "[CV 5/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.001;, score=0.941 total time=   0.1s\n",
            "[CV 1/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.3;, score=0.044 total time=   0.0s\n",
            "[CV 2/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.3;, score=0.099 total time=   0.0s\n",
            "[CV 3/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.3;, score=0.905 total time=   0.0s\n",
            "[CV 4/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.3;, score=0.030 total time=   0.0s\n",
            "[CV 5/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.3;, score=0.112 total time=   0.0s\n",
            "[CV 1/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.5;, score=0.330 total time=   0.0s\n",
            "[CV 2/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.5;, score=0.352 total time=   0.0s\n",
            "[CV 3/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.5;, score=0.527 total time=   0.0s\n",
            "[CV 4/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.5;, score=0.417 total time=   0.0s\n",
            "[CV 5/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.5;, score=0.627 total time=   0.0s\n",
            "[CV 1/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=constant, MLP__learning_rate_init=0.001;, score=0.984 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=constant, MLP__learning_rate_init=0.001;, score=0.857 total time=   0.1s\n",
            "[CV 3/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=constant, MLP__learning_rate_init=0.001;, score=0.947 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=constant, MLP__learning_rate_init=0.001;, score=0.982 total time=   0.1s\n",
            "[CV 5/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=constant, MLP__learning_rate_init=0.001;, score=0.976 total time=   0.1s\n",
            "[CV 1/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=constant, MLP__learning_rate_init=0.3;, score=0.852 total time=   0.0s\n",
            "[CV 2/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=constant, MLP__learning_rate_init=0.3;, score=0.753 total time=   0.0s\n",
            "[CV 3/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=constant, MLP__learning_rate_init=0.3;, score=0.947 total time=   0.0s\n",
            "[CV 4/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=constant, MLP__learning_rate_init=0.3;, score=0.716 total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=constant, MLP__learning_rate_init=0.3;, score=0.947 total time=   0.0s\n",
            "[CV 1/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=constant, MLP__learning_rate_init=0.5;, score=1.000 total time=   0.1s\n",
            "[CV 2/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=constant, MLP__learning_rate_init=0.5;, score=0.978 total time=   0.0s\n",
            "[CV 3/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=constant, MLP__learning_rate_init=0.5;, score=0.444 total time=   0.0s\n",
            "[CV 4/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=constant, MLP__learning_rate_init=0.5;, score=0.976 total time=   0.1s\n",
            "[CV 5/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=constant, MLP__learning_rate_init=0.5;, score=1.000 total time=   0.1s\n",
            "[CV 1/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.001;, score=0.984 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.001;, score=0.857 total time=   0.1s\n",
            "[CV 3/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.001;, score=0.947 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.001;, score=0.982 total time=   0.1s\n",
            "[CV 5/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.001;, score=0.976 total time=   0.1s\n",
            "[CV 1/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.3;, score=0.852 total time=   0.0s\n",
            "[CV 2/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.3;, score=0.753 total time=   0.0s\n",
            "[CV 3/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.3;, score=0.947 total time=   0.0s\n",
            "[CV 4/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.3;, score=0.716 total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.3;, score=0.947 total time=   0.0s\n",
            "[CV 1/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.5;, score=1.000 total time=   0.1s\n",
            "[CV 2/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.5;, score=0.978 total time=   0.0s\n",
            "[CV 3/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.5;, score=0.444 total time=   0.0s\n",
            "[CV 4/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.5;, score=0.976 total time=   0.1s\n",
            "[CV 5/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.5;, score=1.000 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.001;, score=0.984 total time=   0.1s\n",
            "[CV 2/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.001;, score=0.857 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.001;, score=0.947 total time=   0.1s\n",
            "[CV 4/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.001;, score=0.982 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.001;, score=0.976 total time=   0.1s\n",
            "[CV 1/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.3;, score=0.852 total time=   0.0s\n",
            "[CV 2/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.3;, score=0.753 total time=   0.0s\n",
            "[CV 3/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.3;, score=0.947 total time=   0.0s\n",
            "[CV 4/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.3;, score=0.716 total time=   0.0s\n",
            "[CV 5/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.3;, score=0.947 total time=   0.0s\n",
            "[CV 1/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.5;, score=1.000 total time=   0.1s\n",
            "[CV 2/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.5;, score=0.978 total time=   0.0s\n",
            "[CV 3/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.5;, score=0.444 total time=   0.0s\n",
            "[CV 4/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.5;, score=0.976 total time=   0.1s\n",
            "[CV 5/5] END MLP__activation=logistic, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.5;, score=1.000 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.001;, score=1.000 total time=   0.2s\n",
            "[CV 2/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.001;, score=0.912 total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.001;, score=0.988 total time=   0.2s\n",
            "[CV 4/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.001;, score=0.994 total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.001;, score=1.000 total time=   0.2s\n",
            "[CV 1/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.3;, score=0.115 total time=   0.0s\n",
            "[CV 2/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.3;, score=0.044 total time=   0.0s\n",
            "[CV 3/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.3;, score=0.970 total time=   0.0s\n",
            "[CV 4/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.3;, score=0.734 total time=   0.0s\n",
            "[CV 5/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.3;, score=0.547 total time=   0.0s\n",
            "[CV 1/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.5;, score=0.500 total time=   0.0s\n",
            "[CV 2/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.5;, score=0.500 total time=   0.0s\n",
            "[CV 3/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.5;, score=0.462 total time=   0.0s\n",
            "[CV 4/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.5;, score=0.500 total time=   0.0s\n",
            "[CV 5/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.5;, score=0.500 total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.001;, score=1.000 total time=   0.2s\n",
            "[CV 2/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.001;, score=0.912 total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.001;, score=0.988 total time=   0.2s\n",
            "[CV 4/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.001;, score=0.994 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.001;, score=1.000 total time=   0.2s\n",
            "[CV 1/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.3;, score=0.115 total time=   0.0s\n",
            "[CV 2/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.3;, score=0.044 total time=   0.0s\n",
            "[CV 3/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.3;, score=0.970 total time=   0.0s\n",
            "[CV 4/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.3;, score=0.734 total time=   0.0s\n",
            "[CV 5/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.3;, score=0.547 total time=   0.0s\n",
            "[CV 1/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.5;, score=0.500 total time=   0.0s\n",
            "[CV 2/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.5;, score=0.500 total time=   0.0s\n",
            "[CV 3/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.5;, score=0.462 total time=   0.0s\n",
            "[CV 4/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.5;, score=0.500 total time=   0.0s\n",
            "[CV 5/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.5;, score=0.500 total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.001;, score=1.000 total time=   0.2s\n",
            "[CV 2/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.001;, score=0.912 total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.001;, score=0.988 total time=   0.2s\n",
            "[CV 4/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.001;, score=0.994 total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.001;, score=1.000 total time=   0.2s\n",
            "[CV 1/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.3;, score=0.115 total time=   0.0s\n",
            "[CV 2/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.3;, score=0.044 total time=   0.0s\n",
            "[CV 3/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.3;, score=0.970 total time=   0.0s\n",
            "[CV 4/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.3;, score=0.734 total time=   0.0s\n",
            "[CV 5/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.3;, score=0.547 total time=   0.0s\n",
            "[CV 1/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.5;, score=0.500 total time=   0.0s\n",
            "[CV 2/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.5;, score=0.500 total time=   0.0s\n",
            "[CV 3/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.5;, score=0.462 total time=   0.0s\n",
            "[CV 4/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.5;, score=0.500 total time=   0.0s\n",
            "[CV 5/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(20, 10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.5;, score=0.500 total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.001;, score=0.989 total time=   0.1s\n",
            "[CV 2/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.001;, score=0.885 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.001;, score=0.917 total time=   0.1s\n",
            "[CV 4/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.001;, score=1.000 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.001;, score=1.000 total time=   0.2s\n",
            "[CV 1/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.3;, score=0.890 total time=   0.0s\n",
            "[CV 2/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.3;, score=0.945 total time=   0.1s\n",
            "[CV 3/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.3;, score=0.923 total time=   0.0s\n",
            "[CV 4/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.3;, score=0.988 total time=   0.0s\n",
            "[CV 5/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.3;, score=1.000 total time=   0.1s\n",
            "[CV 1/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.5;, score=0.896 total time=   0.0s\n",
            "[CV 2/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.5;, score=0.571 total time=   0.0s\n",
            "[CV 3/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.5;, score=0.994 total time=   0.1s\n",
            "[CV 4/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.5;, score=0.296 total time=   0.0s\n",
            "[CV 5/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=constant, MLP__learning_rate_init=0.5;, score=1.000 total time=   0.0s\n",
            "[CV 1/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.001;, score=0.989 total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.001;, score=0.885 total time=   0.2s\n",
            "[CV 3/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.001;, score=0.917 total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.001;, score=1.000 total time=   0.2s\n",
            "[CV 5/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.001;, score=1.000 total time=   0.2s\n",
            "[CV 1/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.3;, score=0.890 total time=   0.0s\n",
            "[CV 2/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.3;, score=0.945 total time=   0.1s\n",
            "[CV 3/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.3;, score=0.923 total time=   0.0s\n",
            "[CV 4/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.3;, score=0.988 total time=   0.0s\n",
            "[CV 5/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.3;, score=1.000 total time=   0.1s\n",
            "[CV 1/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.5;, score=0.896 total time=   0.0s\n",
            "[CV 2/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.5;, score=0.571 total time=   0.0s\n",
            "[CV 3/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.5;, score=0.994 total time=   0.1s\n",
            "[CV 4/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.5;, score=0.296 total time=   0.0s\n",
            "[CV 5/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.5;, score=1.000 total time=   0.0s\n",
            "[CV 1/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.001;, score=0.989 total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.001;, score=0.885 total time=   0.2s\n",
            "[CV 3/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.001;, score=0.917 total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.001;, score=1.000 total time=   0.2s\n",
            "[CV 5/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.001;, score=1.000 total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.3;, score=0.890 total time=   0.0s\n",
            "[CV 2/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.3;, score=0.945 total time=   0.1s\n",
            "[CV 3/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.3;, score=0.923 total time=   0.1s\n",
            "[CV 4/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.3;, score=0.988 total time=   0.0s\n",
            "[CV 5/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.3;, score=1.000 total time=   0.1s\n",
            "[CV 1/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.5;, score=0.896 total time=   0.0s\n",
            "[CV 2/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.5;, score=0.571 total time=   0.0s\n",
            "[CV 3/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.5;, score=0.994 total time=   0.1s\n",
            "[CV 4/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.5;, score=0.296 total time=   0.0s\n",
            "[CV 5/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(10, 5), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.5;, score=1.000 total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=constant, MLP__learning_rate_init=0.001;, score=0.995 total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=constant, MLP__learning_rate_init=0.001;, score=0.901 total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=constant, MLP__learning_rate_init=0.001;, score=0.941 total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=constant, MLP__learning_rate_init=0.001;, score=1.000 total time=   0.2s\n",
            "[CV 5/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=constant, MLP__learning_rate_init=0.001;, score=0.988 total time=   0.1s\n",
            "[CV 1/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=constant, MLP__learning_rate_init=0.3;, score=1.000 total time=   0.1s\n",
            "[CV 2/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=constant, MLP__learning_rate_init=0.3;, score=0.956 total time=   0.1s\n",
            "[CV 3/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=constant, MLP__learning_rate_init=0.3;, score=0.988 total time=   0.1s\n",
            "[CV 4/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=constant, MLP__learning_rate_init=0.3;, score=0.988 total time=   0.1s\n",
            "[CV 5/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=constant, MLP__learning_rate_init=0.3;, score=0.852 total time=   0.0s\n",
            "[CV 1/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=constant, MLP__learning_rate_init=0.5;, score=1.000 total time=   0.1s\n",
            "[CV 2/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=constant, MLP__learning_rate_init=0.5;, score=0.973 total time=   0.1s\n",
            "[CV 3/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=constant, MLP__learning_rate_init=0.5;, score=0.970 total time=   0.1s\n",
            "[CV 4/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=constant, MLP__learning_rate_init=0.5;, score=0.982 total time=   0.1s\n",
            "[CV 5/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=constant, MLP__learning_rate_init=0.5;, score=1.000 total time=   0.1s\n",
            "[CV 1/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.001;, score=0.995 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.001;, score=0.901 total time=   0.1s\n",
            "[CV 3/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.001;, score=0.941 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.001;, score=1.000 total time=   0.1s\n",
            "[CV 5/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.001;, score=0.988 total time=   0.1s\n",
            "[CV 1/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.3;, score=1.000 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.3;, score=0.956 total time=   0.1s\n",
            "[CV 3/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.3;, score=0.988 total time=   0.1s\n",
            "[CV 4/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.3;, score=0.988 total time=   0.1s\n",
            "[CV 5/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.3;, score=0.852 total time=   0.0s\n",
            "[CV 1/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.5;, score=1.000 total time=   0.1s\n",
            "[CV 2/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.5;, score=0.973 total time=   0.1s\n",
            "[CV 3/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.5;, score=0.970 total time=   0.1s\n",
            "[CV 4/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.5;, score=0.982 total time=   0.1s\n",
            "[CV 5/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=invscaling, MLP__learning_rate_init=0.5;, score=1.000 total time=   0.1s\n",
            "[CV 1/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.001;, score=0.995 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.001;, score=0.901 total time=   0.1s\n",
            "[CV 3/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.001;, score=0.941 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.001;, score=1.000 total time=   0.1s\n",
            "[CV 5/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.001;, score=0.988 total time=   0.1s\n",
            "[CV 1/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.3;, score=1.000 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.3;, score=0.956 total time=   0.1s\n",
            "[CV 3/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.3;, score=0.988 total time=   0.1s\n",
            "[CV 4/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.3;, score=0.988 total time=   0.1s\n",
            "[CV 5/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.3;, score=0.852 total time=   0.0s\n",
            "[CV 1/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.5;, score=1.000 total time=   0.1s\n",
            "[CV 2/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.5;, score=0.973 total time=   0.1s\n",
            "[CV 3/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.5;, score=0.970 total time=   0.1s\n",
            "[CV 4/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.5;, score=0.982 total time=   0.1s\n",
            "[CV 5/5] END MLP__activation=tanh, MLP__hidden_layer_sizes=(50,), MLP__learning_rate=adaptive, MLP__learning_rate_init=0.5;, score=1.000 total time=   0.1s\n",
            "{'MLP__activation': 'tanh', 'MLP__hidden_layer_sizes': (50,), 'MLP__learning_rate': 'constant', 'MLP__learning_rate_init': 0.5}\n",
            "0.9850380388841927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = { 'MLP__hidden_layer_sizes': [(20,10,5),(10,5),(50,)],\n",
        "          'MLP__activation': ['tanh','logistic','identity'],\n",
        "          'MLP__learning_rate':['constant','invscaling','adaptive'],\n",
        "          'MLP__learning_rate_init':[0.001,0.3,0.5]\n",
        "          }\n",
        "\n",
        "kfold = StratifiedKFold(n_splits =5, shuffle = True, random_state = 2022)\n",
        "gcv = GridSearchCV(pipe, param_grid = params, cv = kfold, scoring = 'roc_auc', n_jobs = -1)          \n",
        "gcv.fit(X,y)\n",
        "print(gcv.best_params_)\n",
        "print(gcv.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBWdnWWhKTRD",
        "outputId": "d385bd11-2459-47f3-b847-d01eef559c01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'MLP__activation': 'tanh', 'MLP__hidden_layer_sizes': (50,), 'MLP__learning_rate': 'constant', 'MLP__learning_rate_init': 0.5}\n",
            "0.9850380388841927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP with concrete"
      ],
      "metadata": {
        "id": "t-cvdnr7Ma-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold, GridSearchCV\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "con_path = '/content/gdrive/MyDrive/Datasets/Concrete_Data.csv'\n",
        "concrete = pd.read_csv(con_path)\n",
        "X = concrete.drop('Strength', axis =1 )\n",
        "y = concrete['Strength']\n",
        "\n",
        "mm = MinMaxScaler()\n",
        "mlp = MLPRegressor(random_state =2022)\n",
        "pipe = Pipeline([('MM',mm),('MLP',mlp)])\n",
        "\n",
        "\n",
        "params = { 'MLP__hidden_layer_sizes': [(6,4,3),(7,5),(10,)],\n",
        "          'MLP__learning_rate':['constant','invscaling','adaptive'],\n",
        "          'MLP__learning_rate_init':[0.001,0.3,0.5]\n",
        "          }\n",
        "\n",
        "kfold = KFold(n_splits =5, shuffle = True, random_state = 2022)\n",
        "gcv = GridSearchCV(pipe, param_grid = params, cv = kfold, scoring = 'r2', n_jobs = -1)          \n",
        "gcv.fit(X,y)\n",
        "print(gcv.best_params_)\n",
        "print(gcv.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyLUg3PfMI9O",
        "outputId": "e35ec824-79bb-4a94-a5bf-07569c5e9f4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'MLP__hidden_layer_sizes': (7, 5), 'MLP__learning_rate': 'constant', 'MLP__learning_rate_init': 0.5}\n",
            "0.7053590288937727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "took 23 seconds"
      ],
      "metadata": {
        "id": "b360xQ9NOoIG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP FOR HR Dataset"
      ],
      "metadata": {
        "id": "9ytYX4GMPt_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hr_path = '/content/gdrive/MyDrive/Datasets/human-resources-analytics/HR_comma_sep.csv'\n",
        "hr = pd.read_csv(hr_path)\n",
        "hr_dum = pd.get_dummies(hr, drop_first=True)\n",
        "X = hr_dum.drop('left', axis = 1)\n",
        "y = hr_dum['left']\n",
        "\n",
        "mm = MinMaxScaler()\n",
        "mlp = MLPClassifier(random_state =2022)\n",
        "pipe = Pipeline([('MM',mm),('MLP',mlp)])\n",
        "\n",
        "params = { 'MLP__hidden_layer_sizes': [(20,10,5),(30,20,10),(40,30,10)],\n",
        "          'MLP__activation': ['tanh','logistic','identity'],\n",
        "          'MLP__learning_rate':['constant','invscaling','adaptive'],\n",
        "          'MLP__learning_rate_init':[0.001,0.3,0.5]\n",
        "          }\n",
        "\n",
        "kfold = StratifiedKFold(n_splits =5, shuffle = True, random_state = 2022)\n",
        "gcv = GridSearchCV(pipe, param_grid = params, cv = kfold, scoring = 'roc_auc', n_jobs = -1)          \n",
        "gcv.fit(X,y)\n",
        "print(gcv.best_params_)\n",
        "print(gcv.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ip5mNWPkOpOt",
        "outputId": "71928abb-f48e-4fce-d504-1405986d710f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'MLP__activation': 'tanh', 'MLP__hidden_layer_sizes': (40, 30, 10), 'MLP__learning_rate': 'constant', 'MLP__learning_rate_init': 0.001}\n",
            "0.9846420990748508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit \n",
        "\n",
        "def test(n):\n",
        "    return sum(range(n))\n",
        "\n",
        "n = 10000\n",
        "loop = 1000\n",
        "\n",
        "result = timeit.timeit('test(n)', globals=globals(), number=loop)\n",
        "print(result / loop)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "xbXRqQVDS7aR",
        "outputId": "4f07754e-e575-4eb6-868a-7c5592dc4648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-3e1801d0fa3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\ndef test(n):\\n    return sum(range(n))\\n\\nn = 10000\\nloop = 1000\\n\\nresult = timeit.timeit('test(n)', globals=globals(), number=loop)\\nprint(result / loop)\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2357\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2359\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2360\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m                 \u001b[0mtime_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'timeit' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5ymTfwGLebKS"
      }
    }
  ]
}